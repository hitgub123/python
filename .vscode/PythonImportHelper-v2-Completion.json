[
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "fetch_openml",
        "importPath": "sklearn.datasets",
        "description": "sklearn.datasets",
        "isExtraImport": true,
        "detail": "sklearn.datasets",
        "documentation": {}
    },
    {
        "label": "fetch_openml",
        "importPath": "sklearn.datasets",
        "description": "sklearn.datasets",
        "isExtraImport": true,
        "detail": "sklearn.datasets",
        "documentation": {}
    },
    {
        "label": "fetch_openml",
        "importPath": "sklearn.datasets",
        "description": "sklearn.datasets",
        "isExtraImport": true,
        "detail": "sklearn.datasets",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "torch,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.",
        "description": "torch.",
        "detail": "torch.",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim",
        "description": "torch.optim",
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "DistilBertModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DistilBertTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DistilBertForSequenceClassification",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DistilBertModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DistilBertTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "GPT2Tokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "GPT2LMHeadModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "cosine_similarity",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "cosine_similarity",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "torch,re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.re",
        "description": "torch.re",
        "detail": "torch.re",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "features = pd.read_csv(\"pytorch/learn1/datas/temps.csv\")\n# 独热编码\nfeatures = pd.get_dummies(features)\n# print(features.head(),features.shape)\nyears = features[\"year\"]\nmonths = features[\"month\"]\ndays = features[\"day\"]\ndates = [\"{}-{}-{}\".format(y, m, d) for y, m, d in zip(years, months, days)]\ndates = [datetime.datetime.strptime(date, \"%Y-%m-%d\") for date in dates]\nlabels = features[\"actual\"]",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "features = pd.get_dummies(features)\n# print(features.head(),features.shape)\nyears = features[\"year\"]\nmonths = features[\"month\"]\ndays = features[\"day\"]\ndates = [\"{}-{}-{}\".format(y, m, d) for y, m, d in zip(years, months, days)]\ndates = [datetime.datetime.strptime(date, \"%Y-%m-%d\") for date in dates]\nlabels = features[\"actual\"]\nfeatures = features.drop(\"actual\", axis=1)\nfeatures = features.drop(\"friend\", axis=1)",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "years",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "years = features[\"year\"]\nmonths = features[\"month\"]\ndays = features[\"day\"]\ndates = [\"{}-{}-{}\".format(y, m, d) for y, m, d in zip(years, months, days)]\ndates = [datetime.datetime.strptime(date, \"%Y-%m-%d\") for date in dates]\nlabels = features[\"actual\"]\nfeatures = features.drop(\"actual\", axis=1)\nfeatures = features.drop(\"friend\", axis=1)\ntitles = list(features.columns)\n# print(type(labels),type(features),features.head(),features.shape,titles)",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "months",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "months = features[\"month\"]\ndays = features[\"day\"]\ndates = [\"{}-{}-{}\".format(y, m, d) for y, m, d in zip(years, months, days)]\ndates = [datetime.datetime.strptime(date, \"%Y-%m-%d\") for date in dates]\nlabels = features[\"actual\"]\nfeatures = features.drop(\"actual\", axis=1)\nfeatures = features.drop(\"friend\", axis=1)\ntitles = list(features.columns)\n# print(type(labels),type(features),features.head(),features.shape,titles)\nfeatures = np.array(features, dtype=np.float64)",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "days",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "days = features[\"day\"]\ndates = [\"{}-{}-{}\".format(y, m, d) for y, m, d in zip(years, months, days)]\ndates = [datetime.datetime.strptime(date, \"%Y-%m-%d\") for date in dates]\nlabels = features[\"actual\"]\nfeatures = features.drop(\"actual\", axis=1)\nfeatures = features.drop(\"friend\", axis=1)\ntitles = list(features.columns)\n# print(type(labels),type(features),features.head(),features.shape,titles)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "dates",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "dates = [\"{}-{}-{}\".format(y, m, d) for y, m, d in zip(years, months, days)]\ndates = [datetime.datetime.strptime(date, \"%Y-%m-%d\") for date in dates]\nlabels = features[\"actual\"]\nfeatures = features.drop(\"actual\", axis=1)\nfeatures = features.drop(\"friend\", axis=1)\ntitles = list(features.columns)\n# print(type(labels),type(features),features.head(),features.shape,titles)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "dates",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "dates = [datetime.datetime.strptime(date, \"%Y-%m-%d\") for date in dates]\nlabels = features[\"actual\"]\nfeatures = features.drop(\"actual\", axis=1)\nfeatures = features.drop(\"friend\", axis=1)\ntitles = list(features.columns)\n# print(type(labels),type(features),features.head(),features.shape,titles)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "labels = features[\"actual\"]\nfeatures = features.drop(\"actual\", axis=1)\nfeatures = features.drop(\"friend\", axis=1)\ntitles = list(features.columns)\n# print(type(labels),type(features),features.head(),features.shape,titles)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n# 归一化到 [-1, 1]",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "features = features.drop(\"actual\", axis=1)\nfeatures = features.drop(\"friend\", axis=1)\ntitles = list(features.columns)\n# print(type(labels),type(features),features.head(),features.shape,titles)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n# 归一化到 [-1, 1]\n# min_vals = inputs.min(dim=0, keepdim=True)[0]",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "features = features.drop(\"friend\", axis=1)\ntitles = list(features.columns)\n# print(type(labels),type(features),features.head(),features.shape,titles)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n# 归一化到 [-1, 1]\n# min_vals = inputs.min(dim=0, keepdim=True)[0]\n# max_vals = inputs.max(dim=0, keepdim=True)[0]",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "titles",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "titles = list(features.columns)\n# print(type(labels),type(features),features.head(),features.shape,titles)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n# 归一化到 [-1, 1]\n# min_vals = inputs.min(dim=0, keepdim=True)[0]\n# max_vals = inputs.max(dim=0, keepdim=True)[0]\n# 标准化到 [0, 1]",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "features = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n# 归一化到 [-1, 1]\n# min_vals = inputs.min(dim=0, keepdim=True)[0]\n# max_vals = inputs.max(dim=0, keepdim=True)[0]\n# 标准化到 [0, 1]\n# inputs = (inputs - min_vals) / (max_vals - min_vals).clamp(min=1e-6)\n# print(inputs.size(),labels.shape,inputs)",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "features = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n# 归一化到 [-1, 1]\n# min_vals = inputs.min(dim=0, keepdim=True)[0]\n# max_vals = inputs.max(dim=0, keepdim=True)[0]\n# 标准化到 [0, 1]\n# inputs = (inputs - min_vals) / (max_vals - min_vals).clamp(min=1e-6)\n# print(inputs.size(),labels.shape,inputs)\n#####################################################",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "inputs",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "inputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n# 归一化到 [-1, 1]\n# min_vals = inputs.min(dim=0, keepdim=True)[0]\n# max_vals = inputs.max(dim=0, keepdim=True)[0]\n# 标准化到 [0, 1]\n# inputs = (inputs - min_vals) / (max_vals - min_vals).clamp(min=1e-6)\n# print(inputs.size(),labels.shape,inputs)\n#####################################################\n#################### model ##########################",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "labels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n# 归一化到 [-1, 1]\n# min_vals = inputs.min(dim=0, keepdim=True)[0]\n# max_vals = inputs.max(dim=0, keepdim=True)[0]\n# 标准化到 [0, 1]\n# inputs = (inputs - min_vals) / (max_vals - min_vals).clamp(min=1e-6)\n# print(inputs.size(),labels.shape,inputs)\n#####################################################\n#################### model ##########################\n#####################################################",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "epochs",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "epochs = 1000\nlearn_rate = 0.01\nmodel = tc.nn.Linear(inputs.shape[-1], labels.shape[-1], dtype=tc.float64)\noptimizer = tc.optim.SGD(model.parameters(), lr=learn_rate)\ncriterion = tc.nn.MSELoss()\nfor i in range(epochs):\n    optimizer.zero_grad()\n    outputs = model(inputs)\n    loss = criterion(labels, outputs)\n    loss.backward()",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "learn_rate",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "learn_rate = 0.01\nmodel = tc.nn.Linear(inputs.shape[-1], labels.shape[-1], dtype=tc.float64)\noptimizer = tc.optim.SGD(model.parameters(), lr=learn_rate)\ncriterion = tc.nn.MSELoss()\nfor i in range(epochs):\n    optimizer.zero_grad()\n    outputs = model(inputs)\n    loss = criterion(labels, outputs)\n    loss.backward()\n    optimizer.step()",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "model = tc.nn.Linear(inputs.shape[-1], labels.shape[-1], dtype=tc.float64)\noptimizer = tc.optim.SGD(model.parameters(), lr=learn_rate)\ncriterion = tc.nn.MSELoss()\nfor i in range(epochs):\n    optimizer.zero_grad()\n    outputs = model(inputs)\n    loss = criterion(labels, outputs)\n    loss.backward()\n    optimizer.step()\n    if not i % 100:",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "optimizer = tc.optim.SGD(model.parameters(), lr=learn_rate)\ncriterion = tc.nn.MSELoss()\nfor i in range(epochs):\n    optimizer.zero_grad()\n    outputs = model(inputs)\n    loss = criterion(labels, outputs)\n    loss.backward()\n    optimizer.step()\n    if not i % 100:\n        print(i, loss.item())",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "criterion",
        "kind": 5,
        "importPath": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "description": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "peekOfCode": "criterion = tc.nn.MSELoss()\nfor i in range(epochs):\n    optimizer.zero_grad()\n    outputs = model(inputs)\n    loss = criterion(labels, outputs)\n    loss.backward()\n    optimizer.step()\n    if not i % 100:\n        print(i, loss.item())",
        "detail": "pytorch.learn1.000_2x+1线性回归_01_linear_model",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "features = pd.read_csv(\"pytorch/learn1/datas/temps.csv\")\n# 独热编码\nfeatures = pd.get_dummies(features)\nlabels = features[\"actual\"]\nfeatures = features.drop([\"actual\", \"friend\"], axis=1)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "features = pd.get_dummies(features)\nlabels = features[\"actual\"]\nfeatures = features.drop([\"actual\", \"friend\"], axis=1)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################\n#################### model ##########################\n#####################################################",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "labels = features[\"actual\"]\nfeatures = features.drop([\"actual\", \"friend\"], axis=1)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################\n#################### model ##########################\n#####################################################\nhidden_size = 128",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "features = features.drop([\"actual\", \"friend\"], axis=1)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################\n#################### model ##########################\n#####################################################\nhidden_size = 128\nW1 = tc.rand((inputs.shape[-1], hidden_size), requires_grad=True, dtype=float)",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "features = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################\n#################### model ##########################\n#####################################################\nhidden_size = 128\nW1 = tc.rand((inputs.shape[-1], hidden_size), requires_grad=True, dtype=float)\nB1 = tc.rand(hidden_size, requires_grad=True, dtype=float)",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "features = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################\n#################### model ##########################\n#####################################################\nhidden_size = 128\nW1 = tc.rand((inputs.shape[-1], hidden_size), requires_grad=True, dtype=float)\nB1 = tc.rand(hidden_size, requires_grad=True, dtype=float)\nW2 = tc.rand(hidden_size, 1, requires_grad=True, dtype=float)",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "inputs",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "inputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################\n#################### model ##########################\n#####################################################\nhidden_size = 128\nW1 = tc.rand((inputs.shape[-1], hidden_size), requires_grad=True, dtype=float)\nB1 = tc.rand(hidden_size, requires_grad=True, dtype=float)\nW2 = tc.rand(hidden_size, 1, requires_grad=True, dtype=float)\nB2 = tc.rand(hidden_size, requires_grad=True, dtype=float)",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "labels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################\n#################### model ##########################\n#####################################################\nhidden_size = 128\nW1 = tc.rand((inputs.shape[-1], hidden_size), requires_grad=True, dtype=float)\nB1 = tc.rand(hidden_size, requires_grad=True, dtype=float)\nW2 = tc.rand(hidden_size, 1, requires_grad=True, dtype=float)\nB2 = tc.rand(hidden_size, requires_grad=True, dtype=float)\nepochs = 10000",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "hidden_size",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "hidden_size = 128\nW1 = tc.rand((inputs.shape[-1], hidden_size), requires_grad=True, dtype=float)\nB1 = tc.rand(hidden_size, requires_grad=True, dtype=float)\nW2 = tc.rand(hidden_size, 1, requires_grad=True, dtype=float)\nB2 = tc.rand(hidden_size, requires_grad=True, dtype=float)\nepochs = 10000\nlr = 0.001\nfor i in range(epochs):\n    outputs = inputs.mm(W1) + B1\n    outputs = tc.relu(outputs)",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "W1",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "W1 = tc.rand((inputs.shape[-1], hidden_size), requires_grad=True, dtype=float)\nB1 = tc.rand(hidden_size, requires_grad=True, dtype=float)\nW2 = tc.rand(hidden_size, 1, requires_grad=True, dtype=float)\nB2 = tc.rand(hidden_size, requires_grad=True, dtype=float)\nepochs = 10000\nlr = 0.001\nfor i in range(epochs):\n    outputs = inputs.mm(W1) + B1\n    outputs = tc.relu(outputs)\n    predictions = outputs.mm(W2) + B2",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "B1",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "B1 = tc.rand(hidden_size, requires_grad=True, dtype=float)\nW2 = tc.rand(hidden_size, 1, requires_grad=True, dtype=float)\nB2 = tc.rand(hidden_size, requires_grad=True, dtype=float)\nepochs = 10000\nlr = 0.001\nfor i in range(epochs):\n    outputs = inputs.mm(W1) + B1\n    outputs = tc.relu(outputs)\n    predictions = outputs.mm(W2) + B2\n    loss = tc.mean((predictions - labels) ** 2)",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "W2",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "W2 = tc.rand(hidden_size, 1, requires_grad=True, dtype=float)\nB2 = tc.rand(hidden_size, requires_grad=True, dtype=float)\nepochs = 10000\nlr = 0.001\nfor i in range(epochs):\n    outputs = inputs.mm(W1) + B1\n    outputs = tc.relu(outputs)\n    predictions = outputs.mm(W2) + B2\n    loss = tc.mean((predictions - labels) ** 2)\n    loss.backward()",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "B2",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "B2 = tc.rand(hidden_size, requires_grad=True, dtype=float)\nepochs = 10000\nlr = 0.001\nfor i in range(epochs):\n    outputs = inputs.mm(W1) + B1\n    outputs = tc.relu(outputs)\n    predictions = outputs.mm(W2) + B2\n    loss = tc.mean((predictions - labels) ** 2)\n    loss.backward()\n    if not i % 100:",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "epochs",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "epochs = 10000\nlr = 0.001\nfor i in range(epochs):\n    outputs = inputs.mm(W1) + B1\n    outputs = tc.relu(outputs)\n    predictions = outputs.mm(W2) + B2\n    loss = tc.mean((predictions - labels) ** 2)\n    loss.backward()\n    if not i % 100:\n        print(i, loss)",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "lr",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "peekOfCode": "lr = 0.001\nfor i in range(epochs):\n    outputs = inputs.mm(W1) + B1\n    outputs = tc.relu(outputs)\n    predictions = outputs.mm(W2) + B2\n    loss = tc.mean((predictions - labels) ** 2)\n    loss.backward()\n    if not i % 100:\n        print(i, loss)\n    W1.data.add_(-lr * W1.grad.data)",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_01_mm",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "features = pd.read_csv(\"pytorch/learn1/datas/temps.csv\")\n# 独热编码\nfeatures = pd.get_dummies(features)\nlabels = features[\"actual\"]\nfeatures = features.drop([\"actual\", \"friend\"], axis=1)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "features = pd.get_dummies(features)\nlabels = features[\"actual\"]\nfeatures = features.drop([\"actual\", \"friend\"], axis=1)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################\n#################### model ##########################\n#####################################################",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "labels = features[\"actual\"]\nfeatures = features.drop([\"actual\", \"friend\"], axis=1)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################\n#################### model ##########################\n#####################################################\nhidden_size = 128",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "features = features.drop([\"actual\", \"friend\"], axis=1)\nfeatures = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################\n#################### model ##########################\n#####################################################\nhidden_size = 128\ndata_size = inputs.shape[0]",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "features = np.array(features, dtype=np.float64)\nfeatures = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################\n#################### model ##########################\n#####################################################\nhidden_size = 128\ndata_size = inputs.shape[0]\ninput_size = inputs.shape[-1]",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "features = preprocessing.StandardScaler().fit_transform(features)\ninputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################\n#################### model ##########################\n#####################################################\nhidden_size = 128\ndata_size = inputs.shape[0]\ninput_size = inputs.shape[-1]\noutput_size = 1",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "inputs",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "inputs = tc.tensor(features, dtype=float)\nlabels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################\n#################### model ##########################\n#####################################################\nhidden_size = 128\ndata_size = inputs.shape[0]\ninput_size = inputs.shape[-1]\noutput_size = 1\nbatch_size = 16",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "labels = tc.tensor(np.array(labels).reshape(-1, 1), dtype=float)\n#####################################################\n#################### model ##########################\n#####################################################\nhidden_size = 128\ndata_size = inputs.shape[0]\ninput_size = inputs.shape[-1]\noutput_size = 1\nbatch_size = 16\nlr = 0.001",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "hidden_size",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "hidden_size = 128\ndata_size = inputs.shape[0]\ninput_size = inputs.shape[-1]\noutput_size = 1\nbatch_size = 16\nlr = 0.001\nepochs = 1000\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size, dtype=float),\n    # tc.nn.ReLU(),",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "data_size",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "data_size = inputs.shape[0]\ninput_size = inputs.shape[-1]\noutput_size = 1\nbatch_size = 16\nlr = 0.001\nepochs = 1000\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size, dtype=float),\n    # tc.nn.ReLU(),\n    tc.nn.Sigmoid(),",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "input_size",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "input_size = inputs.shape[-1]\noutput_size = 1\nbatch_size = 16\nlr = 0.001\nepochs = 1000\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size, dtype=float),\n    # tc.nn.ReLU(),\n    tc.nn.Sigmoid(),\n    tc.nn.Linear(hidden_size, output_size, dtype=float),",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "output_size",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "output_size = 1\nbatch_size = 16\nlr = 0.001\nepochs = 1000\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size, dtype=float),\n    # tc.nn.ReLU(),\n    tc.nn.Sigmoid(),\n    tc.nn.Linear(hidden_size, output_size, dtype=float),\n)",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "batch_size = 16\nlr = 0.001\nepochs = 1000\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size, dtype=float),\n    # tc.nn.ReLU(),\n    tc.nn.Sigmoid(),\n    tc.nn.Linear(hidden_size, output_size, dtype=float),\n)\ncost = tc.nn.MSELoss(reduction=\"mean\")",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "lr",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "lr = 0.001\nepochs = 1000\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size, dtype=float),\n    # tc.nn.ReLU(),\n    tc.nn.Sigmoid(),\n    tc.nn.Linear(hidden_size, output_size, dtype=float),\n)\ncost = tc.nn.MSELoss(reduction=\"mean\")\noptimizer = tc.optim.Adam(model.parameters(), lr=lr)",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "epochs",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "epochs = 1000\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size, dtype=float),\n    # tc.nn.ReLU(),\n    tc.nn.Sigmoid(),\n    tc.nn.Linear(hidden_size, output_size, dtype=float),\n)\ncost = tc.nn.MSELoss(reduction=\"mean\")\noptimizer = tc.optim.Adam(model.parameters(), lr=lr)\nfor i in range(epochs):",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "model = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size, dtype=float),\n    # tc.nn.ReLU(),\n    tc.nn.Sigmoid(),\n    tc.nn.Linear(hidden_size, output_size, dtype=float),\n)\ncost = tc.nn.MSELoss(reduction=\"mean\")\noptimizer = tc.optim.Adam(model.parameters(), lr=lr)\nfor i in range(epochs):\n    batch_loss = []",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "cost",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "cost = tc.nn.MSELoss(reduction=\"mean\")\noptimizer = tc.optim.Adam(model.parameters(), lr=lr)\nfor i in range(epochs):\n    batch_loss = []\n    for start in range(0, data_size, batch_size):\n        optimizer.zero_grad()\n        end = start + batch_size if start + batch_size < data_size else data_size\n        x, y = inputs[start:end], labels[start:end]\n        prediction = model(x)\n        loss = cost(prediction, y)",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "optimizer = tc.optim.Adam(model.parameters(), lr=lr)\nfor i in range(epochs):\n    batch_loss = []\n    for start in range(0, data_size, batch_size):\n        optimizer.zero_grad()\n        end = start + batch_size if start + batch_size < data_size else data_size\n        x, y = inputs[start:end], labels[start:end]\n        prediction = model(x)\n        loss = cost(prediction, y)\n        loss.backward()",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "model_name",
        "kind": 5,
        "importPath": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "description": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "peekOfCode": "model_name = \"pytorch/learn1/models/搭建pytorch神经网络进行气温预测.pkl\"\ntc.save(model.state_dict(), model_name)\n# model.load_state_dict(tc.load(model_name,weights_only=0))",
        "detail": "pytorch.learn1.001_搭建pytorch神经网络进行气温预测_02_Sequential",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "def train():\n    for i in range(epochs):\n        batch_loss = []\n        for start in range(0, data_size, batch_size):\n            optimizer.zero_grad()\n            end = start + batch_size if start + batch_size < data_size else data_size\n            x, y = X_train[start:end], y_train[start:end]\n            prediction = model(x)\n            loss = cost(prediction, y)\n            loss.backward()",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "def test():\n    model.load_state_dict(tc.load(model_name, weights_only=0))\n    prediction = model(X_test).argmax(axis=1)\n    acc_rate = (prediction == y_test).sum() / y_test.size()[0]\n    print(acc_rate.item())\n    # print(model)\n    # for i,j in enumerate(model.named_parameters()):\n    #     print(i,j)\nif __name__ == \"__main__\":\n    train()",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "mnist",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "mnist = fetch_openml(\"mnist_784\", version=1, cache=True)\nmnist.target = mnist.target.astype(np.int8)\nX, y = mnist[\"data\"], mnist[\"target\"]\nX[:60000].to_numpy()\nX_train, X_test, y_train, y_test = map(\n    lambda df: df.to_numpy(), (X[:60000], X[60000:], y[:60000], y[60000:])\n)\n# 洗牌训练集\nnp.random.seed(666)\nshuffle_index = np.random.permutation(60000)",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "mnist.target",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "mnist.target = mnist.target.astype(np.int8)\nX, y = mnist[\"data\"], mnist[\"target\"]\nX[:60000].to_numpy()\nX_train, X_test, y_train, y_test = map(\n    lambda df: df.to_numpy(), (X[:60000], X[60000:], y[:60000], y[60000:])\n)\n# 洗牌训练集\nnp.random.seed(666)\nshuffle_index = np.random.permutation(60000)\nX_train, y_train = X_train[shuffle_index], y_train[shuffle_index]",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "shuffle_index",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "shuffle_index = np.random.permutation(60000)\nX_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\nX_train = preprocessing.StandardScaler().fit_transform(X_train)\nX_test = preprocessing.StandardScaler().fit_transform(X_test)\n# y_train = pd.get_dummies(y_train)\n# y_test = pd.get_dummies(y_test)\nX_train, y_train, X_test, y_test = map(tc.tensor, (X_train, y_train, X_test, y_test))\nX_train, X_test = X_train.to(tc.float64), X_test.to(tc.float64)\ny_train, y_test = y_train.to(tc.long), y_test.to(tc.long)\ny_train = tc.nn.functional.one_hot(y_train, num_classes=10)",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "X_train",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "X_train = preprocessing.StandardScaler().fit_transform(X_train)\nX_test = preprocessing.StandardScaler().fit_transform(X_test)\n# y_train = pd.get_dummies(y_train)\n# y_test = pd.get_dummies(y_test)\nX_train, y_train, X_test, y_test = map(tc.tensor, (X_train, y_train, X_test, y_test))\nX_train, X_test = X_train.to(tc.float64), X_test.to(tc.float64)\ny_train, y_test = y_train.to(tc.long), y_test.to(tc.long)\ny_train = tc.nn.functional.one_hot(y_train, num_classes=10)\ny_train = y_train.to(tc.float64)\n#####################################################",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "X_test",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "X_test = preprocessing.StandardScaler().fit_transform(X_test)\n# y_train = pd.get_dummies(y_train)\n# y_test = pd.get_dummies(y_test)\nX_train, y_train, X_test, y_test = map(tc.tensor, (X_train, y_train, X_test, y_test))\nX_train, X_test = X_train.to(tc.float64), X_test.to(tc.float64)\ny_train, y_test = y_train.to(tc.long), y_test.to(tc.long)\ny_train = tc.nn.functional.one_hot(y_train, num_classes=10)\ny_train = y_train.to(tc.float64)\n#####################################################\n#################### model ##########################",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "y_train",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "y_train = tc.nn.functional.one_hot(y_train, num_classes=10)\ny_train = y_train.to(tc.float64)\n#####################################################\n#################### model ##########################\n#####################################################\nhidden_size1 = 128\nhidden_size2 = 70\ndata_size = X_train.shape[0]\ninput_size = X_train.shape[-1]\noutput_size = 10",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "y_train",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "y_train = y_train.to(tc.float64)\n#####################################################\n#################### model ##########################\n#####################################################\nhidden_size1 = 128\nhidden_size2 = 70\ndata_size = X_train.shape[0]\ninput_size = X_train.shape[-1]\noutput_size = 10\nbatch_size = 128",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "hidden_size1",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "hidden_size1 = 128\nhidden_size2 = 70\ndata_size = X_train.shape[0]\ninput_size = X_train.shape[-1]\noutput_size = 10\nbatch_size = 128\nlr = 0.001\nepochs = 200\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "hidden_size2",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "hidden_size2 = 70\ndata_size = X_train.shape[0]\ninput_size = X_train.shape[-1]\noutput_size = 10\nbatch_size = 128\nlr = 0.001\nepochs = 200\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "data_size",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "data_size = X_train.shape[0]\ninput_size = X_train.shape[-1]\noutput_size = 10\nbatch_size = 128\nlr = 0.001\nepochs = 200\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size1, dtype=float),",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "input_size",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "input_size = X_train.shape[-1]\noutput_size = 10\nbatch_size = 128\nlr = 0.001\nepochs = 200\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size1, dtype=float),\n    tc.nn.ReLU(),",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "output_size",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "output_size = 10\nbatch_size = 128\nlr = 0.001\nepochs = 200\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size1, dtype=float),\n    tc.nn.ReLU(),\n    tc.nn.Linear(hidden_size1, hidden_size2, dtype=float),",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "batch_size = 128\nlr = 0.001\nepochs = 200\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size1, dtype=float),\n    tc.nn.ReLU(),\n    tc.nn.Linear(hidden_size1, hidden_size2, dtype=float),\n    tc.nn.ReLU(),",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "lr",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "lr = 0.001\nepochs = 200\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size1, dtype=float),\n    tc.nn.ReLU(),\n    tc.nn.Linear(hidden_size1, hidden_size2, dtype=float),\n    tc.nn.ReLU(),\n    # tc.nn.Sigmoid(),",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "epochs",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "epochs = 200\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size1, dtype=float),\n    tc.nn.ReLU(),\n    tc.nn.Linear(hidden_size1, hidden_size2, dtype=float),\n    tc.nn.ReLU(),\n    # tc.nn.Sigmoid(),\n    tc.nn.Linear(hidden_size2, output_size, dtype=float),",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "model_name",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "model_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size1, dtype=float),\n    tc.nn.ReLU(),\n    tc.nn.Linear(hidden_size1, hidden_size2, dtype=float),\n    tc.nn.ReLU(),\n    # tc.nn.Sigmoid(),\n    tc.nn.Linear(hidden_size2, output_size, dtype=float),\n)",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "model_name",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "model_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size1, dtype=float),\n    tc.nn.ReLU(),\n    tc.nn.Linear(hidden_size1, hidden_size2, dtype=float),\n    tc.nn.ReLU(),\n    # tc.nn.Sigmoid(),\n    tc.nn.Linear(hidden_size2, output_size, dtype=float),\n)\ncost = tc.nn.CrossEntropyLoss()",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "model = tc.nn.Sequential(\n    tc.nn.Linear(input_size, hidden_size1, dtype=float),\n    tc.nn.ReLU(),\n    tc.nn.Linear(hidden_size1, hidden_size2, dtype=float),\n    tc.nn.ReLU(),\n    # tc.nn.Sigmoid(),\n    tc.nn.Linear(hidden_size2, output_size, dtype=float),\n)\ncost = tc.nn.CrossEntropyLoss()\noptimizer = tc.optim.Adam(model.parameters(), lr=lr)",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "cost",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "cost = tc.nn.CrossEntropyLoss()\noptimizer = tc.optim.Adam(model.parameters(), lr=lr)\ndef train():\n    for i in range(epochs):\n        batch_loss = []\n        for start in range(0, data_size, batch_size):\n            optimizer.zero_grad()\n            end = start + batch_size if start + batch_size < data_size else data_size\n            x, y = X_train[start:end], y_train[start:end]\n            prediction = model(x)",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_01_FC",
        "description": "pytorch.learn1.002_mnist预测_01_FC",
        "peekOfCode": "optimizer = tc.optim.Adam(model.parameters(), lr=lr)\ndef train():\n    for i in range(epochs):\n        batch_loss = []\n        for start in range(0, data_size, batch_size):\n            optimizer.zero_grad()\n            end = start + batch_size if start + batch_size < data_size else data_size\n            x, y = X_train[start:end], y_train[start:end]\n            prediction = model(x)\n            loss = cost(prediction, y)",
        "detail": "pytorch.learn1.002_mnist预测_01_FC",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "def train():\n    for i in range(epochs):\n        batch_loss = []\n        for start in range(0, data_size, batch_size):\n            optimizer.zero_grad()\n            end = start + batch_size if start + batch_size < data_size else data_size\n            x, y = X_train[start:end], y_train[start:end]\n            prediction = model(x)\n            loss = cost(prediction, y)\n            loss.backward()",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "def test():\n    model.load_state_dict(tc.load(model_name, weights_only=0))\n    prediction = model(X_test).argmax(axis=1)\n    acc_rate = (prediction == y_test).sum() / y_test.size()[0]\n    print(acc_rate.item())\n    # print(model)\n    # for i,j in enumerate(model.named_parameters()):\n    #     print(i,j)\nif __name__ == \"__main__\":\n    # train()",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "mnist",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "mnist = fetch_openml(\"mnist_784\", version=1, cache=True)\nmnist.target = mnist.target.astype(np.int8)\nX, y = mnist[\"data\"], mnist[\"target\"]\nX[:60000].to_numpy()\nX_train, X_test, y_train, y_test = map(\n    lambda df: df.to_numpy(), (X[:60000], X[60000:], y[:60000], y[60000:])\n)\n# 洗牌训练集\nnp.random.seed(666)\nshuffle_index = np.random.permutation(60000)",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "mnist.target",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "mnist.target = mnist.target.astype(np.int8)\nX, y = mnist[\"data\"], mnist[\"target\"]\nX[:60000].to_numpy()\nX_train, X_test, y_train, y_test = map(\n    lambda df: df.to_numpy(), (X[:60000], X[60000:], y[:60000], y[60000:])\n)\n# 洗牌训练集\nnp.random.seed(666)\nshuffle_index = np.random.permutation(60000)\nX_train, y_train = X_train[shuffle_index], y_train[shuffle_index]",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "shuffle_index",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "shuffle_index = np.random.permutation(60000)\nX_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\nX_train = preprocessing.StandardScaler().fit_transform(X_train)\nX_test = preprocessing.StandardScaler().fit_transform(X_test)\nX_train, y_train, X_test, y_test = map(tc.tensor, (X_train, y_train, X_test, y_test))\nX_train, X_test = X_train.to(tc.float64), X_test.to(tc.float64)\nX_train, X_test = X_train.reshape(-1, 1, 28, 28), X_test.reshape(-1, 1, 28, 28)\ny_train, y_test = y_train.to(tc.long), y_test.to(tc.long)\ny_train = tc.nn.functional.one_hot(y_train, num_classes=10)\ny_train = y_train.to(tc.float64)",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "X_train",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "X_train = preprocessing.StandardScaler().fit_transform(X_train)\nX_test = preprocessing.StandardScaler().fit_transform(X_test)\nX_train, y_train, X_test, y_test = map(tc.tensor, (X_train, y_train, X_test, y_test))\nX_train, X_test = X_train.to(tc.float64), X_test.to(tc.float64)\nX_train, X_test = X_train.reshape(-1, 1, 28, 28), X_test.reshape(-1, 1, 28, 28)\ny_train, y_test = y_train.to(tc.long), y_test.to(tc.long)\ny_train = tc.nn.functional.one_hot(y_train, num_classes=10)\ny_train = y_train.to(tc.float64)\n#####################################################\n#################### model ##########################",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "X_test",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "X_test = preprocessing.StandardScaler().fit_transform(X_test)\nX_train, y_train, X_test, y_test = map(tc.tensor, (X_train, y_train, X_test, y_test))\nX_train, X_test = X_train.to(tc.float64), X_test.to(tc.float64)\nX_train, X_test = X_train.reshape(-1, 1, 28, 28), X_test.reshape(-1, 1, 28, 28)\ny_train, y_test = y_train.to(tc.long), y_test.to(tc.long)\ny_train = tc.nn.functional.one_hot(y_train, num_classes=10)\ny_train = y_train.to(tc.float64)\n#####################################################\n#################### model ##########################\n#####################################################",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "y_train",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "y_train = tc.nn.functional.one_hot(y_train, num_classes=10)\ny_train = y_train.to(tc.float64)\n#####################################################\n#################### model ##########################\n#####################################################\ndata_size = X_train.shape[0]\noutput_size = 10\nbatch_size = 128\nlr = 0.001\nepochs = 30",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "y_train",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "y_train = y_train.to(tc.float64)\n#####################################################\n#################### model ##########################\n#####################################################\ndata_size = X_train.shape[0]\noutput_size = 10\nbatch_size = 128\nlr = 0.001\nepochs = 30\nout_channels1 = 16",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "data_size",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "data_size = X_train.shape[0]\noutput_size = 10\nbatch_size = 128\nlr = 0.001\nepochs = 30\nout_channels1 = 16\nout_channels2 = 32\nkernel_size = 5\nstride = 1\npadding = 2",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "output_size",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "output_size = 10\nbatch_size = 128\nlr = 0.001\nepochs = 30\nout_channels1 = 16\nout_channels2 = 32\nkernel_size = 5\nstride = 1\npadding = 2\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "batch_size = 128\nlr = 0.001\nepochs = 30\nout_channels1 = 16\nout_channels2 = 32\nkernel_size = 5\nstride = 1\npadding = 2\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "lr",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "lr = 0.001\nepochs = 30\nout_channels1 = 16\nout_channels2 = 32\nkernel_size = 5\nstride = 1\npadding = 2\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "epochs",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "epochs = 30\nout_channels1 = 16\nout_channels2 = 32\nkernel_size = 5\nstride = 1\npadding = 2\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Conv2d(  # in:1*28*28,out:16*28*28",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "out_channels1",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "out_channels1 = 16\nout_channels2 = 32\nkernel_size = 5\nstride = 1\npadding = 2\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Conv2d(  # in:1*28*28,out:16*28*28\n        in_channels=1,",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "out_channels2",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "out_channels2 = 32\nkernel_size = 5\nstride = 1\npadding = 2\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Conv2d(  # in:1*28*28,out:16*28*28\n        in_channels=1,\n        out_channels=out_channels1,",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "kernel_size",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "kernel_size = 5\nstride = 1\npadding = 2\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Conv2d(  # in:1*28*28,out:16*28*28\n        in_channels=1,\n        out_channels=out_channels1,\n        kernel_size=kernel_size,",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "stride",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "stride = 1\npadding = 2\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Conv2d(  # in:1*28*28,out:16*28*28\n        in_channels=1,\n        out_channels=out_channels1,\n        kernel_size=kernel_size,\n        stride=stride,",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "padding",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "padding = 2\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Conv2d(  # in:1*28*28,out:16*28*28\n        in_channels=1,\n        out_channels=out_channels1,\n        kernel_size=kernel_size,\n        stride=stride,\n        padding=padding,",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "model_name",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "model_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Conv2d(  # in:1*28*28,out:16*28*28\n        in_channels=1,\n        out_channels=out_channels1,\n        kernel_size=kernel_size,\n        stride=stride,\n        padding=padding,\n        dtype=float,",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "model_name",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "model_name = \"pytorch/learn1/models/{}\".format(model_name)\nmodel = tc.nn.Sequential(\n    tc.nn.Conv2d(  # in:1*28*28,out:16*28*28\n        in_channels=1,\n        out_channels=out_channels1,\n        kernel_size=kernel_size,\n        stride=stride,\n        padding=padding,\n        dtype=float,\n    ),",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "model = tc.nn.Sequential(\n    tc.nn.Conv2d(  # in:1*28*28,out:16*28*28\n        in_channels=1,\n        out_channels=out_channels1,\n        kernel_size=kernel_size,\n        stride=stride,\n        padding=padding,\n        dtype=float,\n    ),\n    tc.nn.ReLU(),",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "cost",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "cost = tc.nn.CrossEntropyLoss()\noptimizer = tc.optim.Adam(model.parameters(), lr=lr)\ndef train():\n    for i in range(epochs):\n        batch_loss = []\n        for start in range(0, data_size, batch_size):\n            optimizer.zero_grad()\n            end = start + batch_size if start + batch_size < data_size else data_size\n            x, y = X_train[start:end], y_train[start:end]\n            prediction = model(x)",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "description": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "peekOfCode": "optimizer = tc.optim.Adam(model.parameters(), lr=lr)\ndef train():\n    for i in range(epochs):\n        batch_loss = []\n        for start in range(0, data_size, batch_size):\n            optimizer.zero_grad()\n            end = start + batch_size if start + batch_size < data_size else data_size\n            x, y = X_train[start:end], y_train[start:end]\n            prediction = model(x)\n            loss = cost(prediction, y)",
        "detail": "pytorch.learn1.002_mnist预测_02_ConvFC",
        "documentation": {}
    },
    {
        "label": "transform_input",
        "kind": 2,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "def transform_input(input_tensor):\n    padded_tensor = tc.nn.functional.pad(\n        input_tensor, (98, 98, 98, 98), mode=\"constant\", value=0\n    )\n    output_tensor = padded_tensor.repeat(1, 3, 1, 1)\n    return output_tensor\nX_test = transform_input(X_test)\n#####################################################\n#################### model ##########################\n#####################################################",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "def train():\n    max_rate = 0\n    writer = SummaryWriter()\n    if os.path.exists(model_name):\n        model_params = tc.load(model_name)\n        model.classifier.load_state_dict(model_params[\"W\"])\n        max_rate = model_params[\"max_rate\"]\n    print(\"max_rate before train : \", max_rate)\n    for i in range(train_epoch):\n        model.train()",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "def test():\n    # model.load_state_dict(tc.load(model_name, weights_only=0))\n    # if os.path.exists(model_name):\n    # model.classifier.load_state_dict(torch.load(model_name))\n    model.eval()\n    acc_count = 0\n    epoch = 2\n    batch_size = 1000\n    for i in range(epoch):\n        prediction = model(",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "mnist",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "mnist = fetch_openml(\"mnist_784\", version=1, cache=True)\nmnist.target = mnist.target.astype(np.int8)\nX, y = mnist[\"data\"], mnist[\"target\"]\ntrain_data_size = 60000  # 60000\nlr = 0.0001\ntrain_epoch = 10\nX[:train_data_size].to_numpy()\nX_train, X_test, y_train, y_test = map(\n    lambda df: df.to_numpy(),\n    (X[:train_data_size], X[60000:], y[:train_data_size], y[60000:]),",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "mnist.target",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "mnist.target = mnist.target.astype(np.int8)\nX, y = mnist[\"data\"], mnist[\"target\"]\ntrain_data_size = 60000  # 60000\nlr = 0.0001\ntrain_epoch = 10\nX[:train_data_size].to_numpy()\nX_train, X_test, y_train, y_test = map(\n    lambda df: df.to_numpy(),\n    (X[:train_data_size], X[60000:], y[:train_data_size], y[60000:]),\n)",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "train_data_size",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "train_data_size = 60000  # 60000\nlr = 0.0001\ntrain_epoch = 10\nX[:train_data_size].to_numpy()\nX_train, X_test, y_train, y_test = map(\n    lambda df: df.to_numpy(),\n    (X[:train_data_size], X[60000:], y[:train_data_size], y[60000:]),\n)\n# 洗牌训练集\nnp.random.seed(666)",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "lr",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "lr = 0.0001\ntrain_epoch = 10\nX[:train_data_size].to_numpy()\nX_train, X_test, y_train, y_test = map(\n    lambda df: df.to_numpy(),\n    (X[:train_data_size], X[60000:], y[:train_data_size], y[60000:]),\n)\n# 洗牌训练集\nnp.random.seed(666)\nshuffle_index = np.random.permutation(train_data_size)",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "train_epoch",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "train_epoch = 10\nX[:train_data_size].to_numpy()\nX_train, X_test, y_train, y_test = map(\n    lambda df: df.to_numpy(),\n    (X[:train_data_size], X[60000:], y[:train_data_size], y[60000:]),\n)\n# 洗牌训练集\nnp.random.seed(666)\nshuffle_index = np.random.permutation(train_data_size)\nX_train, y_train = X_train[shuffle_index], y_train[shuffle_index]",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "shuffle_index",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "shuffle_index = np.random.permutation(train_data_size)\nX_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\nX_train = preprocessing.StandardScaler().fit_transform(X_train)\nX_test = preprocessing.StandardScaler().fit_transform(X_test)\nX_train, y_train, X_test, y_test = map(tc.tensor, (X_train, y_train, X_test, y_test))\nX_train, X_test = X_train.to(tc.float), X_test.to(tc.float)\nX_train, X_test = X_train.reshape(-1, 1, 28, 28), X_test.reshape(-1, 1, 28, 28)\ny_train, y_test = y_train.to(tc.long), y_test.to(tc.long)\ny_train = tc.nn.functional.one_hot(y_train, num_classes=10)\ny_train = y_train.to(tc.float)",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "X_train",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "X_train = preprocessing.StandardScaler().fit_transform(X_train)\nX_test = preprocessing.StandardScaler().fit_transform(X_test)\nX_train, y_train, X_test, y_test = map(tc.tensor, (X_train, y_train, X_test, y_test))\nX_train, X_test = X_train.to(tc.float), X_test.to(tc.float)\nX_train, X_test = X_train.reshape(-1, 1, 28, 28), X_test.reshape(-1, 1, 28, 28)\ny_train, y_test = y_train.to(tc.long), y_test.to(tc.long)\ny_train = tc.nn.functional.one_hot(y_train, num_classes=10)\ny_train = y_train.to(tc.float)\ndef transform_input(input_tensor):\n    padded_tensor = tc.nn.functional.pad(",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "X_test",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "X_test = preprocessing.StandardScaler().fit_transform(X_test)\nX_train, y_train, X_test, y_test = map(tc.tensor, (X_train, y_train, X_test, y_test))\nX_train, X_test = X_train.to(tc.float), X_test.to(tc.float)\nX_train, X_test = X_train.reshape(-1, 1, 28, 28), X_test.reshape(-1, 1, 28, 28)\ny_train, y_test = y_train.to(tc.long), y_test.to(tc.long)\ny_train = tc.nn.functional.one_hot(y_train, num_classes=10)\ny_train = y_train.to(tc.float)\ndef transform_input(input_tensor):\n    padded_tensor = tc.nn.functional.pad(\n        input_tensor, (98, 98, 98, 98), mode=\"constant\", value=0",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "y_train",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "y_train = tc.nn.functional.one_hot(y_train, num_classes=10)\ny_train = y_train.to(tc.float)\ndef transform_input(input_tensor):\n    padded_tensor = tc.nn.functional.pad(\n        input_tensor, (98, 98, 98, 98), mode=\"constant\", value=0\n    )\n    output_tensor = padded_tensor.repeat(1, 3, 1, 1)\n    return output_tensor\nX_test = transform_input(X_test)\n#####################################################",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "y_train",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "y_train = y_train.to(tc.float)\ndef transform_input(input_tensor):\n    padded_tensor = tc.nn.functional.pad(\n        input_tensor, (98, 98, 98, 98), mode=\"constant\", value=0\n    )\n    output_tensor = padded_tensor.repeat(1, 3, 1, 1)\n    return output_tensor\nX_test = transform_input(X_test)\n#####################################################\n#################### model ##########################",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "X_test",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "X_test = transform_input(X_test)\n#####################################################\n#################### model ##########################\n#####################################################\nmodel_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\n# model = models.squeezenet1_(weights=models.squeezenet.SqueezeNet1_0_Weights.DEFAULT)\nmodel = models.squeezenet1_1(weights=models.squeezenet.SqueezeNet1_1_Weights.DEFAULT)\nfor p in model.parameters():\n    p.requires_grad = False",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "model_name",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "model_name = os.path.basename(__file__).replace(\".py\", \".pkl\")\nmodel_name = \"pytorch/learn1/models/{}\".format(model_name)\n# model = models.squeezenet1_(weights=models.squeezenet.SqueezeNet1_0_Weights.DEFAULT)\nmodel = models.squeezenet1_1(weights=models.squeezenet.SqueezeNet1_1_Weights.DEFAULT)\nfor p in model.parameters():\n    p.requires_grad = False\nmodel.classifier = tc.nn.Sequential(\n    tc.nn.Dropout(0.5), tc.nn.Flatten(), tc.nn.Linear(13 * 13 * 512, 10)\n)\ncost = tc.nn.CrossEntropyLoss()",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "model_name",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "model_name = \"pytorch/learn1/models/{}\".format(model_name)\n# model = models.squeezenet1_(weights=models.squeezenet.SqueezeNet1_0_Weights.DEFAULT)\nmodel = models.squeezenet1_1(weights=models.squeezenet.SqueezeNet1_1_Weights.DEFAULT)\nfor p in model.parameters():\n    p.requires_grad = False\nmodel.classifier = tc.nn.Sequential(\n    tc.nn.Dropout(0.5), tc.nn.Flatten(), tc.nn.Linear(13 * 13 * 512, 10)\n)\ncost = tc.nn.CrossEntropyLoss()\noptimizer = tc.optim.Adam(model.classifier.parameters(), lr=lr)",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "model = models.squeezenet1_1(weights=models.squeezenet.SqueezeNet1_1_Weights.DEFAULT)\nfor p in model.parameters():\n    p.requires_grad = False\nmodel.classifier = tc.nn.Sequential(\n    tc.nn.Dropout(0.5), tc.nn.Flatten(), tc.nn.Linear(13 * 13 * 512, 10)\n)\ncost = tc.nn.CrossEntropyLoss()\noptimizer = tc.optim.Adam(model.classifier.parameters(), lr=lr)\ndata_size = X_train.shape[0]\nbatch_size = 32",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "model.classifier",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "model.classifier = tc.nn.Sequential(\n    tc.nn.Dropout(0.5), tc.nn.Flatten(), tc.nn.Linear(13 * 13 * 512, 10)\n)\ncost = tc.nn.CrossEntropyLoss()\noptimizer = tc.optim.Adam(model.classifier.parameters(), lr=lr)\ndata_size = X_train.shape[0]\nbatch_size = 32\n# print(model)\ndef train():\n    max_rate = 0",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "cost",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "cost = tc.nn.CrossEntropyLoss()\noptimizer = tc.optim.Adam(model.classifier.parameters(), lr=lr)\ndata_size = X_train.shape[0]\nbatch_size = 32\n# print(model)\ndef train():\n    max_rate = 0\n    writer = SummaryWriter()\n    if os.path.exists(model_name):\n        model_params = tc.load(model_name)",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "optimizer = tc.optim.Adam(model.classifier.parameters(), lr=lr)\ndata_size = X_train.shape[0]\nbatch_size = 32\n# print(model)\ndef train():\n    max_rate = 0\n    writer = SummaryWriter()\n    if os.path.exists(model_name):\n        model_params = tc.load(model_name)\n        model.classifier.load_state_dict(model_params[\"W\"])",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "data_size",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "data_size = X_train.shape[0]\nbatch_size = 32\n# print(model)\ndef train():\n    max_rate = 0\n    writer = SummaryWriter()\n    if os.path.exists(model_name):\n        model_params = tc.load(model_name)\n        model.classifier.load_state_dict(model_params[\"W\"])\n        max_rate = model_params[\"max_rate\"]",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "description": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "peekOfCode": "batch_size = 32\n# print(model)\ndef train():\n    max_rate = 0\n    writer = SummaryWriter()\n    if os.path.exists(model_name):\n        model_params = tc.load(model_name)\n        model.classifier.load_state_dict(model_params[\"W\"])\n        max_rate = model_params[\"max_rate\"]\n    print(\"max_rate before train : \", max_rate)",
        "detail": "pytorch.learn1.002_mnist预测_03_squeezeNet迁移学习",
        "documentation": {}
    },
    {
        "label": "Generator",
        "kind": 6,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(latent_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, image_dim),\n            nn.Tanh(),  # 输出范围 [-1, 1]，匹配归一化后的图像",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "Discriminator",
        "kind": 6,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(image_dim, hidden_dim),\n            nn.LeakyReLU(0.2),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.LeakyReLU(0.2),\n            nn.Linear(hidden_dim, 1),\n            nn.Sigmoid(),  # 输出概率 [0, 1]",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "train_gan",
        "kind": 2,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "def train_gan():\n    model_name_g = model_util.get_model_name(__file__, \"g\")\n    V_g = model_util.load_model(generator, model_name_g)\n    V_g = sys.maxsize if V_g == 0 else V_g\n    model_name_d = model_util.get_model_name(__file__, \"d\")\n    V_d = model_util.load_model(discriminator, model_name_d)\n    V_d = sys.maxsize if V_d == 0 else V_d\n    for epoch in range(epochs):\n        g_loss_sum, d_loss_sum = 0, 0\n        for i, (real_imgs, _) in enumerate(dataloader):",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "show_images",
        "kind": 2,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "def show_images(images, epoch):\n    fig, axes = plt.subplots(4, 4, figsize=(4, 4))\n    images = images * 0.5 + 0.5  # 反归一化到 [0, 1]\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(images[i].squeeze(), cmap=\"gray\")\n        ax.axis(\"off\")\n    plt.suptitle(f\"Epoch {epoch}\")\n    plt.savefig(f\"gan_output_epoch_{epoch}.png\")\n    plt.close()\n# 开始训练",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "latent_dim",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "latent_dim = 100  # 噪声向量的维度\nhidden_dim = 256  # 隐藏层维度\nimage_dim = 28 * 28  # MNIST 图像展平后的大小 (784)\nbatch_size = 64  # 批量大小\nepochs = 50  # 训练轮数\nlr = 0.0002  # 学习率\ndevice = torch.device(\"cpu\")  # 用 CPU\n# 数据加载和预处理\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]  # 归一化到 [-1, 1]",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "hidden_dim",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "hidden_dim = 256  # 隐藏层维度\nimage_dim = 28 * 28  # MNIST 图像展平后的大小 (784)\nbatch_size = 64  # 批量大小\nepochs = 50  # 训练轮数\nlr = 0.0002  # 学习率\ndevice = torch.device(\"cpu\")  # 用 CPU\n# 数据加载和预处理\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]  # 归一化到 [-1, 1]\n)",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "image_dim",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "image_dim = 28 * 28  # MNIST 图像展平后的大小 (784)\nbatch_size = 64  # 批量大小\nepochs = 50  # 训练轮数\nlr = 0.0002  # 学习率\ndevice = torch.device(\"cpu\")  # 用 CPU\n# 数据加载和预处理\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]  # 归一化到 [-1, 1]\n)\nmnist = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "batch_size = 64  # 批量大小\nepochs = 50  # 训练轮数\nlr = 0.0002  # 学习率\ndevice = torch.device(\"cpu\")  # 用 CPU\n# 数据加载和预处理\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]  # 归一化到 [-1, 1]\n)\nmnist = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\ndataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "epochs",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "epochs = 50  # 训练轮数\nlr = 0.0002  # 学习率\ndevice = torch.device(\"cpu\")  # 用 CPU\n# 数据加载和预处理\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]  # 归一化到 [-1, 1]\n)\nmnist = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\ndataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)\n# 生成器网络",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "lr",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "lr = 0.0002  # 学习率\ndevice = torch.device(\"cpu\")  # 用 CPU\n# 数据加载和预处理\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]  # 归一化到 [-1, 1]\n)\nmnist = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\ndataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)\n# 生成器网络\nclass Generator(nn.Module):",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "device = torch.device(\"cpu\")  # 用 CPU\n# 数据加载和预处理\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]  # 归一化到 [-1, 1]\n)\nmnist = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\ndataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)\n# 生成器网络\nclass Generator(nn.Module):\n    def __init__(self):",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "transform",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "transform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]  # 归一化到 [-1, 1]\n)\nmnist = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\ndataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)\n# 生成器网络\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.model = nn.Sequential(",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "mnist",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "mnist = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\ndataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)\n# 生成器网络\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(latent_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim),",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "dataloader",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "dataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)\n# 生成器网络\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(latent_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "generator",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "generator = Generator().to(device)\ndiscriminator = Discriminator().to(device)\ng_optimizer = optim.Adam(generator.parameters(), lr=lr)\nd_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\ncriterion = nn.BCELoss()  # 二元交叉熵损失\n# 训练函数\ndef train_gan():\n    model_name_g = model_util.get_model_name(__file__, \"g\")\n    V_g = model_util.load_model(generator, model_name_g)\n    V_g = sys.maxsize if V_g == 0 else V_g",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "discriminator",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "discriminator = Discriminator().to(device)\ng_optimizer = optim.Adam(generator.parameters(), lr=lr)\nd_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\ncriterion = nn.BCELoss()  # 二元交叉熵损失\n# 训练函数\ndef train_gan():\n    model_name_g = model_util.get_model_name(__file__, \"g\")\n    V_g = model_util.load_model(generator, model_name_g)\n    V_g = sys.maxsize if V_g == 0 else V_g\n    model_name_d = model_util.get_model_name(__file__, \"d\")",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "g_optimizer",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "g_optimizer = optim.Adam(generator.parameters(), lr=lr)\nd_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\ncriterion = nn.BCELoss()  # 二元交叉熵损失\n# 训练函数\ndef train_gan():\n    model_name_g = model_util.get_model_name(__file__, \"g\")\n    V_g = model_util.load_model(generator, model_name_g)\n    V_g = sys.maxsize if V_g == 0 else V_g\n    model_name_d = model_util.get_model_name(__file__, \"d\")\n    V_d = model_util.load_model(discriminator, model_name_d)",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "d_optimizer",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\ncriterion = nn.BCELoss()  # 二元交叉熵损失\n# 训练函数\ndef train_gan():\n    model_name_g = model_util.get_model_name(__file__, \"g\")\n    V_g = model_util.load_model(generator, model_name_g)\n    V_g = sys.maxsize if V_g == 0 else V_g\n    model_name_d = model_util.get_model_name(__file__, \"d\")\n    V_d = model_util.load_model(discriminator, model_name_d)\n    V_d = sys.maxsize if V_d == 0 else V_d",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "criterion",
        "kind": 5,
        "importPath": "pytorch.learn1.003_gan生成mnist_01_FC",
        "description": "pytorch.learn1.003_gan生成mnist_01_FC",
        "peekOfCode": "criterion = nn.BCELoss()  # 二元交叉熵损失\n# 训练函数\ndef train_gan():\n    model_name_g = model_util.get_model_name(__file__, \"g\")\n    V_g = model_util.load_model(generator, model_name_g)\n    V_g = sys.maxsize if V_g == 0 else V_g\n    model_name_d = model_util.get_model_name(__file__, \"d\")\n    V_d = model_util.load_model(discriminator, model_name_d)\n    V_d = sys.maxsize if V_d == 0 else V_d\n    for epoch in range(epochs):",
        "detail": "pytorch.learn1.003_gan生成mnist_01_FC",
        "documentation": {}
    },
    {
        "label": "RNNClassifier",
        "kind": 6,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "class RNNClassifier(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n        super(RNNClassifier, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    def forward(self, text):\n        # text: [batch_size, max_len]\n        embedded = self.embedding(text)  # [batch_size, max_len, embedding_dim]\n        output, hidden = self.rnn(embedded)  # hidden: [1, batch_size, hidden_dim]",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "build_vocab",
        "kind": 2,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "def build_vocab(texts, max_size=vocab_size):\n    word_counts = Counter()\n    for text in texts:\n        word_counts.update(text.split())\n    common_words = word_counts.most_common(max_size - 2)  # 留出 <PAD> 和 <UNK>\n    vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n    for word, _ in common_words:\n        if re.fullmatch(r\"[a-zA-Z0-9]+\", word):\n            vocab[word] = len(vocab)\n    return vocab",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "text_to_sequence",
        "kind": 2,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "def text_to_sequence(text, vocab, max_len=max_len):\n    seq = [vocab.get(word, 1) for word in text.split()]  # <UNK> 为 1\n    seq = seq[:max_len] + [0] * (max_len - len(seq))  # 填充 <PAD>\n    return seq\n# 数据准备\nvocab = build_vocab(train_data)\nfor i in range(train_data.shape[0]):\n    train_data[i] = np.array(text_to_sequence(train_data[i], vocab))\nfor i in range(test_data.shape[0]):\n    test_data[i] = np.array(text_to_sequence(test_data[i], vocab))",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "handle_data",
        "kind": 2,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "def handle_data(data, label):\n    data = np.concatenate(data).astype(np.int64).reshape(data.shape[0], -1)\n    label = label.astype(np.int64)\n    data = torch.from_numpy(data)\n    label = torch.from_numpy(label)\n    return [(data[i], label[i]) for i in range(data.shape[0])]\ntrain_data_label_handled = handle_data(train_data, train_label)\ntest_data_label_handled = handle_data(test_data, test_label)\ntrain_loader = DataLoader(train_data_label_handled, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data_label_handled, batch_size=batch_size)",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "def train(model, loader, optimizer, criterion):\n    model.train()\n    total_loss = 0\n    for texts, labels in loader:\n        texts, labels = texts.to(device), labels.to(device)\n        optimizer.zero_grad()\n        predictions = model(texts)\n        loss = criterion(predictions, labels)\n        loss.backward()\n        optimizer.step()",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "evaluate",
        "kind": 2,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "def evaluate(model, loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for texts, labels in loader:\n            texts, labels = texts.to(device), labels.to(device)\n            predictions = model(texts)\n            _, predicted = torch.max(predictions, 1)\n            total += labels.size(0)",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "vocab_size",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "vocab_size = 5000  # 词汇表大小\nembedding_dim = 100  # 词嵌入维度\nhidden_dim = 128  # RNN 隐藏层维度\noutput_dim = 4  # 类别数（假设 4 类新闻）\nmax_len = 20  # 最大序列长度(20)\nbatch_size = 32\nepochs = 100\nlr = 0.001\ndevice = torch.device(\"cpu\")  # 用 CPU\ntext_col = 1",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "embedding_dim",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "embedding_dim = 100  # 词嵌入维度\nhidden_dim = 128  # RNN 隐藏层维度\noutput_dim = 4  # 类别数（假设 4 类新闻）\nmax_len = 20  # 最大序列长度(20)\nbatch_size = 32\nepochs = 100\nlr = 0.001\ndevice = torch.device(\"cpu\")  # 用 CPU\ntext_col = 1\ntrain_data_label = pd.read_csv(",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "hidden_dim",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "hidden_dim = 128  # RNN 隐藏层维度\noutput_dim = 4  # 类别数（假设 4 类新闻）\nmax_len = 20  # 最大序列长度(20)\nbatch_size = 32\nepochs = 100\nlr = 0.001\ndevice = torch.device(\"cpu\")  # 用 CPU\ntext_col = 1\ntrain_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/train.csv\", header=None",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "output_dim",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "output_dim = 4  # 类别数（假设 4 类新闻）\nmax_len = 20  # 最大序列长度(20)\nbatch_size = 32\nepochs = 100\nlr = 0.001\ndevice = torch.device(\"cpu\")  # 用 CPU\ntext_col = 1\ntrain_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/train.csv\", header=None\n).to_numpy()",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "max_len",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "max_len = 20  # 最大序列长度(20)\nbatch_size = 32\nepochs = 100\nlr = 0.001\ndevice = torch.device(\"cpu\")  # 用 CPU\ntext_col = 1\ntrain_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/train.csv\", header=None\n).to_numpy()\ntrain_data, train_label = train_data_label[:, text_col], train_data_label[:, 0] - 1",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "batch_size = 32\nepochs = 100\nlr = 0.001\ndevice = torch.device(\"cpu\")  # 用 CPU\ntext_col = 1\ntrain_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/train.csv\", header=None\n).to_numpy()\ntrain_data, train_label = train_data_label[:, text_col], train_data_label[:, 0] - 1\ntest_data_label = pd.read_csv(",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "epochs",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "epochs = 100\nlr = 0.001\ndevice = torch.device(\"cpu\")  # 用 CPU\ntext_col = 1\ntrain_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/train.csv\", header=None\n).to_numpy()\ntrain_data, train_label = train_data_label[:, text_col], train_data_label[:, 0] - 1\ntest_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/test.csv\", header=None",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "lr",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "lr = 0.001\ndevice = torch.device(\"cpu\")  # 用 CPU\ntext_col = 1\ntrain_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/train.csv\", header=None\n).to_numpy()\ntrain_data, train_label = train_data_label[:, text_col], train_data_label[:, 0] - 1\ntest_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/test.csv\", header=None\n).to_numpy()",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "device = torch.device(\"cpu\")  # 用 CPU\ntext_col = 1\ntrain_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/train.csv\", header=None\n).to_numpy()\ntrain_data, train_label = train_data_label[:, text_col], train_data_label[:, 0] - 1\ntest_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/test.csv\", header=None\n).to_numpy()\ntest_data, test_label = test_data_label[:, text_col], test_data_label[:, 0] - 1",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "text_col",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "text_col = 1\ntrain_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/train.csv\", header=None\n).to_numpy()\ntrain_data, train_label = train_data_label[:, text_col], train_data_label[:, 0] - 1\ntest_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/test.csv\", header=None\n).to_numpy()\ntest_data, test_label = test_data_label[:, text_col], test_data_label[:, 0] - 1\ntest_news_lst = test_data_label[:, text_col].copy()",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "train_data_label",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "train_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/train.csv\", header=None\n).to_numpy()\ntrain_data, train_label = train_data_label[:, text_col], train_data_label[:, 0] - 1\ntest_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/test.csv\", header=None\n).to_numpy()\ntest_data, test_label = test_data_label[:, text_col], test_data_label[:, 0] - 1\ntest_news_lst = test_data_label[:, text_col].copy()\n# 数据预处理",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "test_data_label",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "test_data_label = pd.read_csv(\n    \"pytorch/learn1/datas/AG_NEWS/test.csv\", header=None\n).to_numpy()\ntest_data, test_label = test_data_label[:, text_col], test_data_label[:, 0] - 1\ntest_news_lst = test_data_label[:, text_col].copy()\n# 数据预处理\ndef build_vocab(texts, max_size=vocab_size):\n    word_counts = Counter()\n    for text in texts:\n        word_counts.update(text.split())",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "test_news_lst",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "test_news_lst = test_data_label[:, text_col].copy()\n# 数据预处理\ndef build_vocab(texts, max_size=vocab_size):\n    word_counts = Counter()\n    for text in texts:\n        word_counts.update(text.split())\n    common_words = word_counts.most_common(max_size - 2)  # 留出 <PAD> 和 <UNK>\n    vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n    for word, _ in common_words:\n        if re.fullmatch(r\"[a-zA-Z0-9]+\", word):",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "vocab",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "vocab = build_vocab(train_data)\nfor i in range(train_data.shape[0]):\n    train_data[i] = np.array(text_to_sequence(train_data[i], vocab))\nfor i in range(test_data.shape[0]):\n    test_data[i] = np.array(text_to_sequence(test_data[i], vocab))\ndef handle_data(data, label):\n    data = np.concatenate(data).astype(np.int64).reshape(data.shape[0], -1)\n    label = label.astype(np.int64)\n    data = torch.from_numpy(data)\n    label = torch.from_numpy(label)",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "train_data_label_handled",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "train_data_label_handled = handle_data(train_data, train_label)\ntest_data_label_handled = handle_data(test_data, test_label)\ntrain_loader = DataLoader(train_data_label_handled, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data_label_handled, batch_size=batch_size)\n# RNN 模型\nclass RNNClassifier(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n        super(RNNClassifier, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "test_data_label_handled",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "test_data_label_handled = handle_data(test_data, test_label)\ntrain_loader = DataLoader(train_data_label_handled, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data_label_handled, batch_size=batch_size)\n# RNN 模型\nclass RNNClassifier(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n        super(RNNClassifier, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "train_loader",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "train_loader = DataLoader(train_data_label_handled, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data_label_handled, batch_size=batch_size)\n# RNN 模型\nclass RNNClassifier(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n        super(RNNClassifier, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    def forward(self, text):",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "test_loader",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "test_loader = DataLoader(test_data_label_handled, batch_size=batch_size)\n# RNN 模型\nclass RNNClassifier(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n        super(RNNClassifier, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    def forward(self, text):\n        # text: [batch_size, max_len]",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "model = RNNClassifier(vocab_size, embedding_dim, hidden_dim, output_dim).to(device)\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()\n# 训练函数\ndef train(model, loader, optimizer, criterion):\n    model.train()\n    total_loss = 0\n    for texts, labels in loader:\n        texts, labels = texts.to(device), labels.to(device)\n        optimizer.zero_grad()",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "optimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()\n# 训练函数\ndef train(model, loader, optimizer, criterion):\n    model.train()\n    total_loss = 0\n    for texts, labels in loader:\n        texts, labels = texts.to(device), labels.to(device)\n        optimizer.zero_grad()\n        predictions = model(texts)",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "criterion",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "criterion = nn.CrossEntropyLoss()\n# 训练函数\ndef train(model, loader, optimizer, criterion):\n    model.train()\n    total_loss = 0\n    for texts, labels in loader:\n        texts, labels = texts.to(device), labels.to(device)\n        optimizer.zero_grad()\n        predictions = model(texts)\n        loss = criterion(predictions, labels)",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "model_name",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "model_name = model_util.get_model_name(__file__)\nmax_acc = model_util.load_model(model, model_name)\nprint(\"max_acc\", max_acc)\nfor epoch in range(epochs):\n    train_loss = train(model, train_loader, optimizer, criterion)\n    test_acc = evaluate(model, test_loader)\n    print(\n        f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Acc: {test_acc:.4f}\"\n    )\n    if max_acc < test_acc:",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "max_acc",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "max_acc = model_util.load_model(model, model_name)\nprint(\"max_acc\", max_acc)\nfor epoch in range(epochs):\n    train_loss = train(model, train_loader, optimizer, criterion)\n    test_acc = evaluate(model, test_loader)\n    print(\n        f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Acc: {test_acc:.4f}\"\n    )\n    if max_acc < test_acc:\n        max_acc = test_acc",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "classes",
        "kind": 5,
        "importPath": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "description": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "peekOfCode": "classes = [\"World\", \"Sports\", \"Business\", \"Science/Technology\"]\nfor i in range(10):\n    test_news = test_news_lst[i]\n    seq = test_data[i].to(device)\n    actual = test_label[i]\n    with torch.no_grad():\n        pred = model(seq)\n        label = torch.argmax(pred).item()\n        print(f\"News: {test_news}, Predicted: {classes[label]},Result: {actual==label}\")",
        "detail": "pytorch.learn1.004_基于RNN的新闻分类_01",
        "documentation": {}
    },
    {
        "label": "RAGGenerator",
        "kind": 6,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "class RAGGenerator(nn.Module):\n    def __init__(self, num_labels):\n        super(RAGGenerator, self).__init__()\n        self.distilbert = DistilBertForSequenceClassification.from_pretrained(\n            \"distilbert-base-uncased\", num_labels=num_labels\n        )\n        # 冻结大部分层，只微调分类头\n        for param in self.distilbert.distilbert.parameters():\n            param.requires_grad = False  # 冻结 Transformer 层\n    def forward(self, input_ids, attention_mask):",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "RAGDataset",
        "kind": 6,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "class RAGDataset(Dataset):\n    def __init__(self, queries, answers):\n        self.queries = queries\n        self.answers = answers\n    def __len__(self):\n        return len(self.queries)\n    def __getitem__(self, idx):\n        query = self.queries[idx]\n        retrieved = retrieve(query)[0]  # 检索到的答案\n        inputs = tokenizer(",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "get_embedding",
        "kind": 2,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "def get_embedding(text):\n    inputs = tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length\n    ).to(device)\n    with torch.no_grad():\n        outputs = bert_model(**inputs)\n    return outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()  # CLS 向量\ndoc_embeddings = [get_embedding(doc[\"question\"]) for doc in documents]\n# 检索函数\ndef retrieve(query, top_k=1):",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "retrieve",
        "kind": 2,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "def retrieve(query, top_k=1):\n    query_emb = get_embedding(query)\n    similarities = cosine_similarity([query_emb], doc_embeddings)[0]\n    top_idx = np.argsort(similarities)[-top_k:][::-1]\n    return [documents[idx][\"answer\"] for idx in top_idx]\n# 生成模型（DistilBERT for Sequence Classification）\nclass RAGGenerator(nn.Module):\n    def __init__(self, num_labels):\n        super(RAGGenerator, self).__init__()\n        self.distilbert = DistilBertForSequenceClassification.from_pretrained(",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "def train(model, dataloader, epochs=100):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for input_ids, attention_mask, targets in dataloader:\n            input_ids, attention_mask, targets = (\n                input_ids.to(device),\n                attention_mask.to(device),\n                targets.to(device),\n            )",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "rag_demo",
        "kind": 2,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "def rag_demo(query):\n    retrieved = retrieve(query)[0]\n    print(f\"Retrieved: {retrieved}\")\n    inputs = tokenizer(\n        retrieved,\n        return_tensors=\"pt\",\n        truncation=True,\n        padding=\"max_length\",\n        max_length=max_length,\n    ).to(device)",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "embedding_dim",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "embedding_dim = 768  # DistilBERT 输出维度\nbatch_size = 3  # 小批量，CPU 友好\nmax_length = 20  # 短序列，减少内存(max_length = 20)\nnum_labels = 3  # 假设 3 个回答类别（简化）\ndevice = torch.device(\"cpu\")\n# 模拟文档数据集（FAQ）\ndocuments = [\n    {\"question\": \"什么是人工智能？\", \"answer\": \"人工智能是模拟人类智能的技术。\"},\n    {\"question\": \"机器学习怎么工作？\", \"answer\": \"机器学习通过数据训练模型。\"},\n    {\"question\": \"深度学习有什么用？\", \"answer\": \"深度学习用于图像和语言处理。\"},",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "batch_size = 3  # 小批量，CPU 友好\nmax_length = 20  # 短序列，减少内存(max_length = 20)\nnum_labels = 3  # 假设 3 个回答类别（简化）\ndevice = torch.device(\"cpu\")\n# 模拟文档数据集（FAQ）\ndocuments = [\n    {\"question\": \"什么是人工智能？\", \"answer\": \"人工智能是模拟人类智能的技术。\"},\n    {\"question\": \"机器学习怎么工作？\", \"answer\": \"机器学习通过数据训练模型。\"},\n    {\"question\": \"深度学习有什么用？\", \"answer\": \"深度学习用于图像和语言处理。\"},\n]",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "max_length",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "max_length = 20  # 短序列，减少内存(max_length = 20)\nnum_labels = 3  # 假设 3 个回答类别（简化）\ndevice = torch.device(\"cpu\")\n# 模拟文档数据集（FAQ）\ndocuments = [\n    {\"question\": \"什么是人工智能？\", \"answer\": \"人工智能是模拟人类智能的技术。\"},\n    {\"question\": \"机器学习怎么工作？\", \"answer\": \"机器学习通过数据训练模型。\"},\n    {\"question\": \"深度学习有什么用？\", \"answer\": \"深度学习用于图像和语言处理。\"},\n]\n# 加载 DistilBERT（用于检索嵌入）",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "num_labels",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "num_labels = 3  # 假设 3 个回答类别（简化）\ndevice = torch.device(\"cpu\")\n# 模拟文档数据集（FAQ）\ndocuments = [\n    {\"question\": \"什么是人工智能？\", \"answer\": \"人工智能是模拟人类智能的技术。\"},\n    {\"question\": \"机器学习怎么工作？\", \"answer\": \"机器学习通过数据训练模型。\"},\n    {\"question\": \"深度学习有什么用？\", \"answer\": \"深度学习用于图像和语言处理。\"},\n]\n# 加载 DistilBERT（用于检索嵌入）\ntokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "device = torch.device(\"cpu\")\n# 模拟文档数据集（FAQ）\ndocuments = [\n    {\"question\": \"什么是人工智能？\", \"answer\": \"人工智能是模拟人类智能的技术。\"},\n    {\"question\": \"机器学习怎么工作？\", \"answer\": \"机器学习通过数据训练模型。\"},\n    {\"question\": \"深度学习有什么用？\", \"answer\": \"深度学习用于图像和语言处理。\"},\n]\n# 加载 DistilBERT（用于检索嵌入）\ntokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\nbert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "documents",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "documents = [\n    {\"question\": \"什么是人工智能？\", \"answer\": \"人工智能是模拟人类智能的技术。\"},\n    {\"question\": \"机器学习怎么工作？\", \"answer\": \"机器学习通过数据训练模型。\"},\n    {\"question\": \"深度学习有什么用？\", \"answer\": \"深度学习用于图像和语言处理。\"},\n]\n# 加载 DistilBERT（用于检索嵌入）\ntokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\nbert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\nbert_model.eval()\n# 生成文档嵌入",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "tokenizer",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\nbert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\nbert_model.eval()\n# 生成文档嵌入\ndef get_embedding(text):\n    inputs = tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length\n    ).to(device)\n    with torch.no_grad():\n        outputs = bert_model(**inputs)",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "bert_model",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "bert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\nbert_model.eval()\n# 生成文档嵌入\ndef get_embedding(text):\n    inputs = tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length\n    ).to(device)\n    with torch.no_grad():\n        outputs = bert_model(**inputs)\n    return outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()  # CLS 向量",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "doc_embeddings",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "doc_embeddings = [get_embedding(doc[\"question\"]) for doc in documents]\n# 检索函数\ndef retrieve(query, top_k=1):\n    query_emb = get_embedding(query)\n    similarities = cosine_similarity([query_emb], doc_embeddings)[0]\n    top_idx = np.argsort(similarities)[-top_k:][::-1]\n    return [documents[idx][\"answer\"] for idx in top_idx]\n# 生成模型（DistilBERT for Sequence Classification）\nclass RAGGenerator(nn.Module):\n    def __init__(self, num_labels):",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "queries",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "queries = [\"人工智能是什么？\", \"机器学习如何运作？\", \"深度学习的应用有哪些？\"]\nanswers = [\n    \"人工智能是模拟人类智能的技术。\",\n    \"机器学习通过数据训练模型。\",\n    \"深度学习用于图像和语言处理。\",\n]\ndataset = RAGDataset(queries, answers)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n# 初始化模型\ngenerator = RAGGenerator(num_labels).to(device)",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "answers",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "answers = [\n    \"人工智能是模拟人类智能的技术。\",\n    \"机器学习通过数据训练模型。\",\n    \"深度学习用于图像和语言处理。\",\n]\ndataset = RAGDataset(queries, answers)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n# 初始化模型\ngenerator = RAGGenerator(num_labels).to(device)\noptimizer = torch.optim.Adam(generator.parameters(), lr=2e-5)  # 小学习率",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "dataset",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "dataset = RAGDataset(queries, answers)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n# 初始化模型\ngenerator = RAGGenerator(num_labels).to(device)\noptimizer = torch.optim.Adam(generator.parameters(), lr=2e-5)  # 小学习率\ncriterion = nn.CrossEntropyLoss()\n# 训练\ndef train(model, dataloader, epochs=100):\n    model.train()\n    for epoch in range(epochs):",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "dataloader",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n# 初始化模型\ngenerator = RAGGenerator(num_labels).to(device)\noptimizer = torch.optim.Adam(generator.parameters(), lr=2e-5)  # 小学习率\ncriterion = nn.CrossEntropyLoss()\n# 训练\ndef train(model, dataloader, epochs=100):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "generator",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "generator = RAGGenerator(num_labels).to(device)\noptimizer = torch.optim.Adam(generator.parameters(), lr=2e-5)  # 小学习率\ncriterion = nn.CrossEntropyLoss()\n# 训练\ndef train(model, dataloader, epochs=100):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for input_ids, attention_mask, targets in dataloader:\n            input_ids, attention_mask, targets = (",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "optimizer = torch.optim.Adam(generator.parameters(), lr=2e-5)  # 小学习率\ncriterion = nn.CrossEntropyLoss()\n# 训练\ndef train(model, dataloader, epochs=100):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for input_ids, attention_mask, targets in dataloader:\n            input_ids, attention_mask, targets = (\n                input_ids.to(device),",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "criterion",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_01_DistilBERT",
        "description": "pytorch.learn1.005_RAG_01_DistilBERT",
        "peekOfCode": "criterion = nn.CrossEntropyLoss()\n# 训练\ndef train(model, dataloader, epochs=100):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for input_ids, attention_mask, targets in dataloader:\n            input_ids, attention_mask, targets = (\n                input_ids.to(device),\n                attention_mask.to(device),",
        "detail": "pytorch.learn1.005_RAG_01_DistilBERT",
        "documentation": {}
    },
    {
        "label": "RAGDataset",
        "kind": 6,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "class RAGDataset(Dataset):\n    def __init__(self, queries, answers):\n        self.queries = queries\n        self.answers = answers\n    def __len__(self):\n        return len(self.queries)\n    def __getitem__(self, idx):\n        query = self.queries[idx]\n        retrieved = retrieve(query)[0]\n        # 输入：检索到的答案作为提示",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "get_embedding",
        "kind": 2,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "def get_embedding(text):\n    inputs = bert_tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length\n    ).to(device)\n    with torch.no_grad():\n        outputs = bert_model(**inputs)\n    return outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\ndoc_embeddings = [get_embedding(doc[\"question\"]) for doc in documents]\n# 检索函数\ndef retrieve(query, top_k=1):",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "retrieve",
        "kind": 2,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "def retrieve(query, top_k=1):\n    query_emb = get_embedding(query)\n    similarities = cosine_similarity([query_emb], doc_embeddings)[0]\n    top_idx = np.argsort(similarities)[-top_k:][::-1]\n    return [documents[idx][\"answer\"] for idx in top_idx]\n# 数据集\nclass RAGDataset(Dataset):\n    def __init__(self, queries, answers):\n        self.queries = queries\n        self.answers = answers",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "def train(model, dataloader, epochs=10):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for input_ids, attention_mask, target_ids in dataloader:\n            input_ids, attention_mask, target_ids = (\n                input_ids.to(device),\n                attention_mask.to(device),\n                target_ids.to(device),\n            )",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "rag_demo",
        "kind": 2,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "def rag_demo(query):\n    retrieved = retrieve(query)[0]\n    print(f\"Retrieved: {retrieved}\")\n    input_text = f\"回答: {retrieved}\"\n    inputs = gpt2_tokenizer(\n        input_text,\n        return_tensors=\"pt\",\n        truncation=True,\n        padding=\"max_length\",\n        max_length=max_length,",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "embedding_dim",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "embedding_dim = 768  # DistilBERT 用于检索\nbatch_size = 1\nmax_length = 20  # 输入和生成的最大长度\ndevice = torch.device(\"cpu\")\n# 数据集\ndocuments = [\n    {\"question\": \"什么是人工智能？\", \"answer\": \"人工智能是模拟人类智能的技术。\"},\n    {\"question\": \"机器学习怎么工作？\", \"answer\": \"机器学习通过数据训练模型。\"},\n    {\"question\": \"深度学习有什么用？\", \"answer\": \"深度学习用于图像和语言处理。\"},\n]",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "batch_size = 1\nmax_length = 20  # 输入和生成的最大长度\ndevice = torch.device(\"cpu\")\n# 数据集\ndocuments = [\n    {\"question\": \"什么是人工智能？\", \"answer\": \"人工智能是模拟人类智能的技术。\"},\n    {\"question\": \"机器学习怎么工作？\", \"answer\": \"机器学习通过数据训练模型。\"},\n    {\"question\": \"深度学习有什么用？\", \"answer\": \"深度学习用于图像和语言处理。\"},\n]\nqueries = [\"人工智能是什么？\", \"机器学习如何运作？\", \"深度学习能做什么？\"]",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "max_length",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "max_length = 20  # 输入和生成的最大长度\ndevice = torch.device(\"cpu\")\n# 数据集\ndocuments = [\n    {\"question\": \"什么是人工智能？\", \"answer\": \"人工智能是模拟人类智能的技术。\"},\n    {\"question\": \"机器学习怎么工作？\", \"answer\": \"机器学习通过数据训练模型。\"},\n    {\"question\": \"深度学习有什么用？\", \"answer\": \"深度学习用于图像和语言处理。\"},\n]\nqueries = [\"人工智能是什么？\", \"机器学习如何运作？\", \"深度学习能做什么？\"]\nanswers = [",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "device = torch.device(\"cpu\")\n# 数据集\ndocuments = [\n    {\"question\": \"什么是人工智能？\", \"answer\": \"人工智能是模拟人类智能的技术。\"},\n    {\"question\": \"机器学习怎么工作？\", \"answer\": \"机器学习通过数据训练模型。\"},\n    {\"question\": \"深度学习有什么用？\", \"answer\": \"深度学习用于图像和语言处理。\"},\n]\nqueries = [\"人工智能是什么？\", \"机器学习如何运作？\", \"深度学习能做什么？\"]\nanswers = [\n    \"人工智能是模拟人类智能的技术。\",",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "documents",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "documents = [\n    {\"question\": \"什么是人工智能？\", \"answer\": \"人工智能是模拟人类智能的技术。\"},\n    {\"question\": \"机器学习怎么工作？\", \"answer\": \"机器学习通过数据训练模型。\"},\n    {\"question\": \"深度学习有什么用？\", \"answer\": \"深度学习用于图像和语言处理。\"},\n]\nqueries = [\"人工智能是什么？\", \"机器学习如何运作？\", \"深度学习能做什么？\"]\nanswers = [\n    \"人工智能是模拟人类智能的技术。\",\n    \"机器学习通过数据训练模型。\",\n    \"深度学习用于图像和语言处理。\",",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "queries",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "queries = [\"人工智能是什么？\", \"机器学习如何运作？\", \"深度学习能做什么？\"]\nanswers = [\n    \"人工智能是模拟人类智能的技术。\",\n    \"机器学习通过数据训练模型。\",\n    \"深度学习用于图像和语言处理。\",\n]\n# 加载模型和分词器\nbert_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\nbert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\nbert_model.eval()",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "answers",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "answers = [\n    \"人工智能是模拟人类智能的技术。\",\n    \"机器学习通过数据训练模型。\",\n    \"深度学习用于图像和语言处理。\",\n]\n# 加载模型和分词器\nbert_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\nbert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\nbert_model.eval()\ngpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "bert_tokenizer",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "bert_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\nbert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\nbert_model.eval()\ngpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\ngpt2_model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\").to(device)\n# 为 GPT2 添加 pad token（DistilGPT2 默认无 padding）\ngpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\ngpt2_model.config.pad_token_id = gpt2_tokenizer.eos_token_id\n# 生成嵌入（用于检索）\ndef get_embedding(text):",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "bert_model",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "bert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\nbert_model.eval()\ngpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\ngpt2_model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\").to(device)\n# 为 GPT2 添加 pad token（DistilGPT2 默认无 padding）\ngpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\ngpt2_model.config.pad_token_id = gpt2_tokenizer.eos_token_id\n# 生成嵌入（用于检索）\ndef get_embedding(text):\n    inputs = bert_tokenizer(",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "gpt2_tokenizer",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\ngpt2_model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\").to(device)\n# 为 GPT2 添加 pad token（DistilGPT2 默认无 padding）\ngpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\ngpt2_model.config.pad_token_id = gpt2_tokenizer.eos_token_id\n# 生成嵌入（用于检索）\ndef get_embedding(text):\n    inputs = bert_tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length\n    ).to(device)",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "gpt2_model",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "gpt2_model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\").to(device)\n# 为 GPT2 添加 pad token（DistilGPT2 默认无 padding）\ngpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\ngpt2_model.config.pad_token_id = gpt2_tokenizer.eos_token_id\n# 生成嵌入（用于检索）\ndef get_embedding(text):\n    inputs = bert_tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length\n    ).to(device)\n    with torch.no_grad():",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "gpt2_tokenizer.pad_token",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\ngpt2_model.config.pad_token_id = gpt2_tokenizer.eos_token_id\n# 生成嵌入（用于检索）\ndef get_embedding(text):\n    inputs = bert_tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length\n    ).to(device)\n    with torch.no_grad():\n        outputs = bert_model(**inputs)\n    return outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "gpt2_model.config.pad_token_id",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "gpt2_model.config.pad_token_id = gpt2_tokenizer.eos_token_id\n# 生成嵌入（用于检索）\ndef get_embedding(text):\n    inputs = bert_tokenizer(\n        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length\n    ).to(device)\n    with torch.no_grad():\n        outputs = bert_model(**inputs)\n    return outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\ndoc_embeddings = [get_embedding(doc[\"question\"]) for doc in documents]",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "doc_embeddings",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "doc_embeddings = [get_embedding(doc[\"question\"]) for doc in documents]\n# 检索函数\ndef retrieve(query, top_k=1):\n    query_emb = get_embedding(query)\n    similarities = cosine_similarity([query_emb], doc_embeddings)[0]\n    top_idx = np.argsort(similarities)[-top_k:][::-1]\n    return [documents[idx][\"answer\"] for idx in top_idx]\n# 数据集\nclass RAGDataset(Dataset):\n    def __init__(self, queries, answers):",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "dataset",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "dataset = RAGDataset(queries, answers)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n# 冻结部分层（优化 CPU）\n# for param in gpt2_model.transformer.parameters():\n#     param.requires_grad = False  # 冻结 Transformer 层，只训输出层\n# optimizer = torch.optim.Adam(gpt2_model.parameters(), lr=2e-5)\n# 冻结 Transformer 层\nfor param in gpt2_model.transformer.parameters():\n    param.requires_grad = False  # 只冻结 Transformer，输出层仍可训练\nfor param in gpt2_model.lm_head.parameters():",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "dataloader",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n# 冻结部分层（优化 CPU）\n# for param in gpt2_model.transformer.parameters():\n#     param.requires_grad = False  # 冻结 Transformer 层，只训输出层\n# optimizer = torch.optim.Adam(gpt2_model.parameters(), lr=2e-5)\n# 冻结 Transformer 层\nfor param in gpt2_model.transformer.parameters():\n    param.requires_grad = False  # 只冻结 Transformer，输出层仍可训练\nfor param in gpt2_model.lm_head.parameters():\n    param.requires_grad = True  # 确保输出层可训练",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "optimizer = torch.optim.Adam(\n    filter(lambda p: p.requires_grad, gpt2_model.parameters()), lr=2e-5\n)\ncriterion = nn.CrossEntropyLoss(ignore_index=gpt2_tokenizer.pad_token_id)\n# 训练\ndef train(model, dataloader, epochs=10):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for input_ids, attention_mask, target_ids in dataloader:",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "criterion",
        "kind": 5,
        "importPath": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "description": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "peekOfCode": "criterion = nn.CrossEntropyLoss(ignore_index=gpt2_tokenizer.pad_token_id)\n# 训练\ndef train(model, dataloader, epochs=10):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for input_ids, attention_mask, target_ids in dataloader:\n            input_ids, attention_mask, target_ids = (\n                input_ids.to(device),\n                attention_mask.to(device),",
        "detail": "pytorch.learn1.005_RAG_02_DistilGPT2",
        "documentation": {}
    },
    {
        "label": "get_model_name",
        "kind": 2,
        "importPath": "pytorch.learn1.model_util",
        "description": "pytorch.learn1.model_util",
        "peekOfCode": "def get_model_name(base_file_name,suffix=None):\n    if suffix:\n        model_name = os.path.basename(base_file_name).replace(\".py\", f\"_{suffix}.pkl\")\n    else:\n        model_name = os.path.basename(base_file_name).replace(\".py\", \".pkl\")\n    model_name = f\"pytorch/learn1/models/{model_name}\"\n    return model_name\ndef save_model(model, model_name, V):\n    torch.save({\"V\": V, \"W\": model.state_dict()}, model_name)\ndef load_model(model, model_name):",
        "detail": "pytorch.learn1.model_util",
        "documentation": {}
    },
    {
        "label": "save_model",
        "kind": 2,
        "importPath": "pytorch.learn1.model_util",
        "description": "pytorch.learn1.model_util",
        "peekOfCode": "def save_model(model, model_name, V):\n    torch.save({\"V\": V, \"W\": model.state_dict()}, model_name)\ndef load_model(model, model_name):\n    V = 0\n    if os.path.exists(model_name):\n        model_params = torch.load(model_name)\n        model.load_state_dict(model_params[\"W\"])\n        V = model_params[\"V\"]\n    return V",
        "detail": "pytorch.learn1.model_util",
        "documentation": {}
    },
    {
        "label": "load_model",
        "kind": 2,
        "importPath": "pytorch.learn1.model_util",
        "description": "pytorch.learn1.model_util",
        "peekOfCode": "def load_model(model, model_name):\n    V = 0\n    if os.path.exists(model_name):\n        model_params = torch.load(model_name)\n        model.load_state_dict(model_params[\"W\"])\n        V = model_params[\"V\"]\n    return V",
        "detail": "pytorch.learn1.model_util",
        "documentation": {}
    }
]